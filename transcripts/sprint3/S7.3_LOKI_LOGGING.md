# S7.3: Loki Logging Stack

**Video Duration:** ~10 minutes  
**Story Points:** 3

---

## Learning Objectives

By the end of this video, you will be able to:
- Understand Loki architecture
- Install Loki and Promtail
- Query logs in Grafana
- Correlate logs with metrics

---

## Transcript

### Introduction (0:00 - 1:00)

Welcome back! Metrics tell you WHAT is happening. Logs tell you WHY. We need both!

Loki is like Prometheus but for logs. It uses the same label-based approach, integrates perfectly with Grafana, and is much cheaper than Elasticsearch.

### Loki Architecture (1:00 - 2:00)

*[Shows architecture]*

**Promtail** - Agent on each node, collects and ships logs
**Loki** - Stores and indexes logs (by labels, not full-text)
**Grafana** - Query and visualize logs

The secret sauce: Loki only indexes labels (like pod name, namespace), not log content. This makes it very efficient and cost-effective.

### Installing Loki Stack (2:00 - 4:00)

```bash
helm repo add grafana https://grafana.github.io/helm-charts

helm install loki grafana/loki-stack \
  -n monitoring \
  -f monitoring/loki-values.yaml
```

Our values file:

```yaml
# loki-values.yaml
loki:
  persistence:
    enabled: true
    size: 20Gi

promtail:
  enabled: true
  config:
    clients:
      - url: http://loki:3100/loki/api/v1/push
```

Let's verify:

```bash
kubectl get pods -n monitoring -l app=loki
kubectl get pods -n monitoring -l app=promtail
```

Promtail runs as a DaemonSet - one pod per node.

### Viewing Logs in Grafana (4:00 - 6:00)

*[Opens Grafana → Explore → Select Loki]*

Let's query our application logs:

```logql
{namespace="techitfactory"}
```

*[Shows logs streaming]*

All logs from all pods in our namespace!

Filter by service:

```logql
{namespace="techitfactory", app="api-gateway"}
```

Search for errors:

```logql
{namespace="techitfactory"} |= "error"
```

Or use regex:

```logql
{namespace="techitfactory"} |~ "status=(4|5)[0-9]{2}"
```

### Log Aggregation Queries (6:00 - 7:30)

Count logs per service:

```logql
sum by (app) (count_over_time({namespace="techitfactory"}[5m]))
```

Error rate from logs:

```logql
sum(count_over_time({namespace="techitfactory"} |= "error"[5m])) 
/ 
sum(count_over_time({namespace="techitfactory"}[5m])) * 100
```

These can power dashboards!

### Correlating Logs and Metrics (7:30 - 9:00)

The power of unified observability:

*[Shows Grafana with metrics panel]*

1. See spike in error rate (metrics)
2. Click and select time range
3. Switch to Explore
4. Query logs for that time window

```logql
{namespace="techitfactory", app="api-gateway"} |= "error"
```

*[Shows logs from that time period]*

Now you know WHAT happened (metrics) and WHY (logs)!

### Log Retention (9:00 - 9:30)

Configure retention in Loki:

```yaml
loki:
  config:
    table_manager:
      retention_deletes_enabled: true
      retention_period: 168h  # 7 days
```

Logs older than 7 days are automatically deleted.

### Summary (9:30 - 10:00)

We deployed:
1. Loki for log aggregation
2. Promtail for log collection
3. LogQL for querying
4. Grafana integration

Now we have metrics AND logs in one place!

---

## Key Takeaways

- Loki indexes labels, not log content
- Promtail collects logs from all pods
- LogQL is similar to PromQL
- Correlate metrics and logs for faster debugging
- Configure retention to manage storage
